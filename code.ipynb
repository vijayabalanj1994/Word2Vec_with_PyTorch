{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e158f3-835d-4057-b7fc-cdc74db8d60c",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8d877ff-0389-48b5-b0ca-673062517dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijay\\AppData\\Local\\Temp\\ipykernel_19496\\2207896738.py:29: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, SVG\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.vocab import GloVe, vocab\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "\n",
    "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from IPython.core.display import display, SVG\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f402e5d-908b-4106-9dc0-94bd0e32e48f",
   "metadata": {},
   "source": [
    "#### Defing a funtion to plot word embeddings in 2d space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26911e8e-34c9-46b5-8340-064fe7bbde7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(word_embeddings, vocab=vocab):\n",
    "\n",
    "    # performing t-SNE on the embeddings to reduce their dimentionality to 2D using \"TSNE\" function from \"sklearn\" libary\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    word_embeddings_2d = tsne.fit_transform(word_embeddings)\n",
    "\n",
    "    # plotting the results with labels from vocab\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i, word in enumerate(vocab.get_itos()):\n",
    "        plt.scatter(word_embeddings_2d[i,0], word_embeddings_2d[i,1])\n",
    "        plt.annotate(word, (word_embeddings_2d[i,0], word_embeddings_2d[i,1]))\n",
    "\n",
    "    plt.xlabel(\"t-SNE component 1\")\n",
    "    plt.ylabel(\"t-SNE component 2\")\n",
    "    plt.title(\"Word Embeddings visualized with t-SNE\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4fa2fe-c052-40f5-a666-adee3c9be188",
   "metadata": {},
   "source": [
    "#### Defining a function to return similar words to a given word by calculating Cosine distance~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfd70ddc-7a3b-40d4-badd-1dea878efe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_word(word, word_embeddings, top_k=5):\n",
    "    if word not in word_embeddings:\n",
    "        print(\"Word not found in embeddings.\")\n",
    "        return []\n",
    "\n",
    "    target_embedding = word_embeddings[word]\n",
    "\n",
    "    # calculating cosine distange with all words\n",
    "    similarities = {}\n",
    "    for w, embedding in word_embeddings.items():\n",
    "        if w != word:\n",
    "            similarity = torch.dot(target_embedding, embedding) / (torch.norm(traget_embedding) * torch.norm(embedding))\n",
    "            similarities[w] = similarity.item()\n",
    "\n",
    "    # soting the similarities\n",
    "    sorted_similarities = sorted(similarities.items(), key= lambda x: x[1], reverse=True)\n",
    "\n",
    "    # returning the tok k similar words\n",
    "    most_similar_word = [w for w, _ in sorted_similarities[:tok_k]]\n",
    "    return most_similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf76ce1-1497-4e42-b287-b8703038a595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
